services:
  db:
    image: postgres:16-alpine
    container_name: forecast-db
    restart: unless-stopped
    labels:
      - "forecast.license.stop=true"
    environment:
      POSTGRES_USER: ${DB_USER:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}
      POSTGRES_DB: ${DB_NAME:-forecaster_enterprise}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-postgres}"]
      interval: 30s
      timeout: 10s
      retries: 3

  backend:
    build: ./backend
    container_name: forecast-backend
    restart: unless-stopped
    labels:
      - "forecast.license.stop=true"
    ports:
      - "8000:8000"
    volumes:
      - ./data:/data:ro
      # Shared volume for ML model cache (persists across releases)
      # Models downloaded once, reused on every backend restart/update
      - ml_models_cache:/root/.cache/huggingface
      - ml_pip_cache:/root/.cache/pip
    env_file:
      - .env
    environment:
      # Database connection (credentials from .env file)
      - DB_HOST=db
      # sslmode=disable is safe here - traffic stays within Docker's isolated network
      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@db:5432/${DB_NAME}?sslmode=disable

      # Application
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DEBUG=${DEBUG:-false}

      # First-time setup (override in .env if needed)
      - SETUP_TEST_DATA=${SETUP_TEST_DATA:-false}
      - CLIENT_NAME=${CLIENT_NAME:-Demo Client}
      - CSV_PATH=${CSV_PATH:-/data/synthetic_data/synthetic_ecom_chronos2_demo.csv}
      - TEST_EMAIL=${TEST_EMAIL:-}
      - TEST_PASSWORD=${TEST_PASSWORD:-}
      - TEST_NAME=${TEST_NAME:-Test User}
    depends_on:
      db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  frontend:
    build: ./frontend
    container_name: forecast-frontend
    restart: unless-stopped
    ports:
      - "3000:3000"
    volumes:
      - license_data:/license-data:ro
    environment:
      # Nuxt uses NUXT_ prefix for runtime config override
      - NUXT_API_BASE_URL=http://backend:8000
      - NUXT_PUBLIC_API_BASE_URL=${NUXT_PUBLIC_API_BASE_URL:-http://localhost:8000}
      - NUXT_SESSION_PASSWORD=${NUXT_SESSION_PASSWORD}
      # License grace period (must match license-watcher)
      - LICENSE_GRACE_PERIOD=${GRACE_PERIOD:-172800}
    depends_on:
      backend:
        condition: service_healthy
      license-watcher:
        condition: service_started
    healthcheck:
      test:
        [
          "CMD",
          "node",
          "-e",
          "require('http').get('http://localhost:3000/api/health', (r) => process.exit(r.statusCode === 200 ? 0 : 1)).on('error', () => process.exit(1))",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  license-watcher:
    build: ./licence-checker
    container_name: forecast-licence-watcher
    restart: on-failure:5
    environment:
      LICENSE_URL: ${LICENSE_URL}
      LICENSE_KEY: ${LICENSE_KEY}
      CHECK_INTERVAL: ${CHECK_INTERVAL:-3600}
      GRACE_PERIOD: ${GRACE_PERIOD:-172800}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - license_data:/data
      - license_data:/license-data

  cloudflared:
    image: cloudflare/cloudflared
    container_name: cloudflare-tunnel
    restart: unless-stopped
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${TUNNEL_TOKEN}
volumes:
  postgres_data:
  license_data:
  # ML model cache - persists across backend container updates
  # HuggingFace models (Chronos-2) cached here
  ml_models_cache:
  # Python package cache for PyTorch/ML dependencies
  ml_pip_cache:
